description: LangRec CLI
arguments:
  model:
    help: Model name
    required: true
    type: str
    choices:
      - SENTENCEBERT
      - SENTENCET5
      - QWEN2_7B
      - QWEN2_1_5B
      - QWEN2_0_5B
      - DEEPSEEKR1QWEN_7B
      - MISTRAL7B
      - PHI3_7B
      - PHI2_3B
      - RECGPT7B
      - LLAMA1
      - LLAMA2
      - LLAMA3
      - LLAMA3_1
      - BERTBASE
      - BERTLARGE
      - P5BEAUTY_SMALL
      - P5BEAUTY_BASE
  dataset:
    help: Dataset name
    required: true
    type: str
    choices:
      - GOODREADS
      - MOVIELENS
      - STEAM
  task:
    help: Recommendation task to perform
    required: false
    type: str
    choices:
      - ctr
      - drec
      - seq
    default: drec
  metrics:
    help: Comma-separated list of metrics to use for evaluation.
    required: false
    type: list
    list_style: comma
    default: "NDCG@10,MRR,Recall@10,AUC,GAUC"
  history_window:
    help: The length of the user behavior history window. For a positive value N, the first N items are taken from history. For a negative value N, the last N items are taken.
    required: false
    type: int
    default: -20
  source:
    help: The subset used
    required: false
    type: str
    choices:
      - original
      - test
      - finetune
    default: test
  mode:
    help: Test, finetune or test&tune the model
    required: false
    type: str
    choices:
      - test
      - finetune
      - testtune
    default: test
  type:
    required: false
    type: str
    choices:
      - prompt
      - embed
    default: prompt
  rerun:
    required: false
    type: bool
    default: false
  embed_func:
    required: false
    type: str
    choices:
      - last
      - pool
    default: last
  latency:
    required: false
    type: bool
    default: false
  gpu:
    help: The number of GPU to use. Enter -1 to use CPU.
    required: false
    type: int
  seed:
    help: The seed for RNG.
    required: false
    type: int
    default: 4141
  batch_size:
    help: Size of batches used in finetuning
    required: false
    type: int
    default: 16
  tune_from:
    help: Layer from which he finetuning begins
    required: false
    type: int
    default: 0
  use_lora:
    help: Toggles the usage of LoRA finetuning technique
    required: false
    type: bool
    default: true
  lora_r:
    required: false
    type: int
    default: 16
  lora_alpha:
    required: false
    type: int
    default: 32
  lora_dropout:
    help: The probability that a trainable parameter will be artificially set to zero for a given batch of training
    required: false
    type: float
    default: 0.1
  valid_ratio:
    help: Part of finetune set used for validation
    required: false
    type: float
    default: 0.1
  valid_metric:
    help: Metric used to evaluate models on validation step
    required: false
    type: str
    default: 'GAUC'
  lr:
    help: Learning rate
    required: false
    type: float
    default: 0.0001
  eval_interval:
    help: Evaluation interval
    required: false
    type: int
    default: 0
  acc_batch:
    help: Batch size for accumulative step
    required: false
    type: int
    default: 1
  align_step:
    help: Step size for alignment method of class Tuner
    required: false
    type: float
    default: 1.0
  patience:
    help:
    required: false
    type: int
    default: 2
  num_epochs:
    required: false
    type: int
    default: 3
  code_path:
    help: The path to item representation encodings
    required: false
    type: str
  alignment:
    required: false
    type: bool
    default: false
  valid_step:
    required: false
    type: int
    default: 1
  search_mode:
    required: false
    type: str
    choices:
      - list
      - tree
      - prod
    default: prod
  search_width:
    required: false
    type: int
    default: 20