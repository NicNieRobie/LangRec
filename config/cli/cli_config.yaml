description: LangRec CLI
arguments:
  model:
    help: Model name
    required: true
    type: str
    choices:
      - SENTENCEBERT
      - SENTENCET5
      - QWEN2_7B
      - QWEN2_1_5B
      - QWEN2_0_5B
      - DEEPSEEKR1QWEN_7B
      - MISTRAL7B
      - PHI3_7B
      - PHI2_3B
      - RECGPT7B
      - LLAMA1
      - LLAMA2
      - LLAMA3
      - LLAMA3_1
      - BERTBASE
      - BERTLARGE
      - P5BEAUTY_SMALL
      - P5BEAUTY_BASE
  dataset:
    help: Dataset name
    required: true
    type: str
    choices:
      - MOVIELENS
  task:
    help: Recommendation task to perform
    required: false
    type: str
    choices:
      - ctr
      - drec
      - seq
    default: drec
  metrics:
    help: Comma-separated list of metrics to use for evaluation.
    required: false
    type: list
    list_style: comma
    default: "NDCG@10,MRR,Recall@10,AUC,GAUC"
  history_window:
    help: The length of the user behavior history window. For a positive value N, the first N items are taken from history. For a negative value N, the last N items are taken.
    required: false
    type: int
    default: -20
  source:
    help: The subset used
    required: false
    type: str
    choices:
      - original
      - test
      - finetune
    default: test
  mode:
    help: Test, finetune or test&tune the model
    required: false
    type: str
    choices:
      - test
      - finetune
      - testtune
    default: test
  type:
    required: false
    type: str
    choices:
      - prompt
      - embed
    default: prompt
  rerun:
    required: false
    type: bool
    default: false
  embed_func:
    required: false
    type: str
    choices:
      - last
      - pool
    default: last
  latency:
    required: false
    type: bool
    default: false
  gpu:
    help: The number of GPU to use. Enter -1 to use CPU.
    required: false
    type: int
  seed:
    help: The seed for RNG.
    required: false
    type: int
    default: 4141
  batch_size:
    help: Size of batches used in finetuning
    required: false
    type: int
    default: 16
  tune_from:
    help: Layer from which he finetuning begins
    required: false
    type: int
    default: 0
  use_lora:
    help: Toggles the usage of LoRA finetuning technique
    required: false
    type: bool
    default: true
  lora_r:
    required: false
    type: int
    default: 16
  lora_alpha:
    required: false
    type: int
    default: 32
  lora_dropout:
    help: The probability that a trainable parameter will be artificially set to zero for a given batch of training
    required: false
    type: float
    default: 0.1
  valid_ratio:
    help: Part of finetune set used for validation
    required: false
    type: float
    default: 0.1
  valid_metric:
    help: Metric used to evaluate models on validation step
    required: false
    type: str
    default: 'GAUC'
  lr:
    help: Learning rate
    required: false
    type: float
    default: 0.0001
  eval_interval:
    help: Evaluation interval
    required: false
    type: int
    default: 0
  acc_batch:
    help: Batch size for accumulative step
    required: false
    type: int
    default: 1
  align_step:
    help: Step size for alignment method of class Tuner
    required: false
    type: float
    default: 1.0
  patience:
    help:
    required: false
    type: int
    default: 2
  num_epochs:
    required: false
    type: int
    default: 3
  code_path:
    help: The path to item representation encodings
    required: false
    type: str
  code_type:
    help: The type of item representation used
    required: false
    type: str
    choices:
      - id
      - sid
  enc_model:
    help: Model used for encoding semantic IDs
    required: false
    type: str
    choices:
      - SENTENCEBERT
      - SENTENCET5
    default: SENTENCET5
  alignment:
    required: false
    type: bool
    default: false
  valid_step:
    required: false
    type: int
    default: 1
  search_mode:
    required: false
    type: str
    choices:
      - list
      - tree
      - prod
    default: prod
  search_width:
    required: false
    type: int
    default: 20
  rqvae_attrs:
    help: Comma-separated list of item features to be included
    required: false
    type: list
    list_style: comma
  rqvae_e_dim:
    help: Codebook embedding size
    required: false
    type: int
    default: 32
  rqvae_layer_sizes:
    help: Comma-separated list of latent space sizes for every RQ-VAE layer
    required: false
    type: list
    list_style: comma
    default: "2048,1024,512,256,128,64"
  rqvae_num_emb_list:
    help: Comma-separated list of numbers of embeddings at every VQ layer
    required: false
    type: list
    list_style: comma
    default: "256,256,256,256"
  rqvae_dropout_prob:
    help: Dropout probability
    required: false
    type: float
    default: 0.0
  rqvae_bn:
    help: Flag for using batch normalization
    required: false
    type: bool
    default: false
  rqvae_loss_type:
    help: Loss type
    required: false
    type: str
    choices:
      - MSE
      - L1
    default: MSE
  rqvae_quant_loss_weight:
    help: VQ quantization loss weight
    required: false
    type: float
    default: 1.0
  rqvae_beta:
    help: Beta for commitment loss
    required: false
    type: float
    default: 0.25
  rqvae_kmeans_init:
    help: Flag for initializing VQ via k-means
    required: false
    type: bool
    default: true
  rqvae_kmeans_iters:
    help: Max number of k-means iterations
    required: false
    type: int
    default: 100
  rqvae_sk_epsilons:
    help: Comma-separated list of Sinkhorn algorithm epsilons
    required: false
    type: list
    list_style: comma
    default: "0.0,0.0,0.0,0.003"
  rqvae_sk_iters:
    help: Max number of Sinkhorn algorithm iterations
    required: false
    type: int
    default: 50
  num_workers:
    help: The number of workers for handling data (CPU-bound)
    required: false
    type: int
    default: 4
  rqvae_batch_size:
    help: Batch size for training RQ-VAE
    required: false
    type: int
    default: 2048
  rqvae_lr:
    help: Learning rate
    required: false
    type: float
    default: 0.001
  rqvae_lr_scheduler_type:
    help: Scheduler
    required: false
    type: str
    choices:
      - LINEAR
      - CONSTANT
    default: CONSTANT
  rqvae_optimizer:
    help: Optimizer
    required: false
    type: str
    choices:
      - ADAM
      - SGD
      - ADAGRAD
      - RMSPROP
      - ADAMW
    default: ADAMW
  rqvae_weight_decay:
    help: L2 regularization coefficient
    required: false
    type: float
    default: 0.0
  rqvae_epochs:
    help: The number of epochs
    required: false
    type: int
    default: 100
  rqvae_warmup_epochs:
    help: The number of warmup epochs
    required: false
    type: int
    default: 50
  rqvae_save_limit:
    help: The maximum number of saved checkpoints
    required: false
    type: int
    default: 5
  rqvae_eval_step:
    help: The step frequency of evaluation
    required: false
    type: int
    default: 50